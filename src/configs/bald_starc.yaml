# base_config.yaml

# Simulation parameters
simulation:
  epochs: 25
  batch_size: 10
  full_retrain: True
  kl_budget: 3.5

exp_name: "bald_starc"
seed: 9

train_dataset:
  class: CompleteTrajectoryDataset

eval_dataset:
  class: CompleteTrajectoryDataset

# Model parameters
pref_model:
  class: EnsemblePreferenceModel
  model:
    input_size: 40
    layers: "[10, 5]"
    init_func: "xavier_uniform"
    activation_fn: "tanh"
  lr: 0.01
  train_test_split: 0.2
  train_batch_size: 10
  eval_batch_size: 1000
  num_epochs: 1000
  early_stopping_patience: 50
  early_stopping: True
  ensemble_size: 10
  standardize_features: True

reward_standardizer: 
  class: StarcRewardStandardizer

gt_pref_model:
  class: GaussianLatentPreferenceModel
  mean: 1.0
  sigma: 0.4

policy:
  class: UniformPolicy
  action_space_lb: 0
  action_space_ub: 1

# Data parameters
data:
  state_space_lb: 0
  state_space_ub: 1
  train_size: 3000
  test_size: 3000

# Trainer parameters
trainer: 
  class: BoltzmannBoNPolicyTrainer

# Data Selection Parameters
data_selection:
  policy: BALDSelectionPolicy